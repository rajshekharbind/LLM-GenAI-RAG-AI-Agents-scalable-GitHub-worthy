# LLM-GenAI-RAG-AI-Agents-Scalable

A comprehensive learning and implementation repository for building scalable AI applications using LangChain, featuring LLMs, Chat Models, RAG systems, AI Agents, and advanced prompt engineering techniques.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Quick Start](#quick-start)
- [Technologies](#technologies)
- [Key Components](#key-components)
- [Examples](#examples)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This repository contains production-ready implementations of:
- **Large Language Models (LLMs)** - Integration with OpenAI, HuggingFace, and other providers
- **Chat Models** - Multi-provider chat model implementations
- **Embedding Models** - Document embedding and semantic search
- **RAG (Retrieval Augmented Generation)** - Complete RAG pipeline with vector stores
- **AI Agents** - Intelligent agents with tools and toolkits
- **Advanced Chains** - Sequential, parallel, and conditional processing chains
- **Structured Output** - Pydantic and TypedDict for type-safe outputs
- **Prompt Engineering** - Advanced prompt templates and optimization techniques

## ğŸ“ Project Structure

```
LANG-CHAINS/
â”œâ”€â”€ 1.LLMs/                          # LLM implementations
â”‚   â”œâ”€â”€ 1_llm_demo.py
â”‚   â”œâ”€â”€ stroutputparser.py
â”‚   â””â”€â”€ stroutputparser_json.py
â”‚
â”œâ”€â”€ 2.ChatModels/                    # Chat model integrations
â”‚   â”œâ”€â”€ ChatModel_Open_api.py
â”‚   â”œâ”€â”€ chatmode_anthropic.py
â”‚   â”œâ”€â”€ chatmode_google.py
â”‚   â”œâ”€â”€ 4_chatmodel_hf_api.py
â”‚   â””â”€â”€ 5_chatmodel_hf_local.py
â”‚
â”œâ”€â”€ 3.EmbededModels/                 # Embedding models & similarity search
â”‚   â”œâ”€â”€ 1_embided_model.py
â”‚   â””â”€â”€ document_similarty.py
â”‚
â”œâ”€â”€ chains/                          # Chain patterns
â”‚   â”œâ”€â”€ simple_chain.py
â”‚   â”œâ”€â”€ sequential_chain.py
â”‚   â”œâ”€â”€ parallel_chain.py
â”‚   â””â”€â”€ conditional_chain.py
â”‚
â”œâ”€â”€ dictionary/                      # Data structure patterns
â”‚   â”œâ”€â”€ pydantic_demo.py
â”‚   â”œâ”€â”€ typed_dic.py
â”‚   â”œâ”€â”€ with_structured_output_pydantic.py
â”‚   â””â”€â”€ with_structured_output_typeddict.py
â”‚
â”œâ”€â”€ prompt/                          # Prompt engineering
â”‚   â”œâ”€â”€ prompt_template.py
â”‚   â”œâ”€â”€ chat_prompt_template.py
â”‚   â”œâ”€â”€ message_placeholder.py
â”‚   â”œâ”€â”€ chatbot.py
â”‚   â”œâ”€â”€ prompt_ui.py
â”‚   â”œâ”€â”€ temperature.py
â”‚   â””â”€â”€ prompt_generator.py
â”‚
â”œâ”€â”€ RAG-APPLICATION/                 # Complete RAG implementation
â”‚   â”œâ”€â”€ langchain-document-loder/
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”‚   â”œâ”€â”€ csv_loader.py
â”‚   â”‚   â”œâ”€â”€ text_loader.py
â”‚   â”‚   â”œâ”€â”€ directory_loader.py
â”‚   â”‚   â””â”€â”€ webbase_loader.py
â”‚   â”œâ”€â”€ langchain-text-spilitter/
â”‚   â”‚   â”œâ”€â”€ length_based.py
â”‚   â”‚   â”œâ”€â”€ markdown_splitting.py
â”‚   â”‚   â”œâ”€â”€ python_code_splitting.py
â”‚   â”‚   â”œâ”€â”€ semantic_meaning_based.py
â”‚   â”‚   â””â”€â”€ text_structure_based.py
â”‚   â”œâ”€â”€ vector-store/
â”‚   â”‚   â”œâ”€â”€ vector_store_demo.py
â”‚   â”‚   â””â”€â”€ chroma_db/
â”‚   â”œâ”€â”€ Tools/
â”‚   â”‚   â”œâ”€â”€ Custom-Tools.py
â”‚   â”‚   â”œâ”€â”€ Built-in-Tool - DuckDuckGo-Search.py
â”‚   â”‚   â”œâ”€â”€ Built-in-Tool - Shell-Tool.py
â”‚   â”‚   â””â”€â”€ Using-StructuredTool.py
â”‚   â”œâ”€â”€ Toolkit/
â”‚   â”‚   â””â”€â”€ toolkit.py
â”‚   â”œâ”€â”€ BaseTool-Class/
â”‚   â”‚   â””â”€â”€ basetool.py
â”‚   â””â”€â”€ Youtube-Chatbot-rag/
â”‚       â”œâ”€â”€ app.py
â”‚       â”œâ”€â”€ youtube-rag-app.py
â”‚       â””â”€â”€ templates/index.html
â”‚
â”œâ”€â”€ Runnables-in-LangChain/          # LangChain Runnables patterns
â”‚   â”œâ”€â”€ runnable_lambda.py
â”‚   â”œâ”€â”€ runnable_sequence.py
â”‚   â”œâ”€â”€ runnable_parallel.py
â”‚   â”œâ”€â”€ runnable_branch.py
â”‚   â”œâ”€â”€ runnable_passthrough.py
â”‚   â”œâ”€â”€ llmchain.py
â”‚   â”œâ”€â”€ retrievalQAchain.py
â”‚   â””â”€â”€ simple_llm_app.py
â”‚
â”œâ”€â”€ structure/                       # Structure demos
â”‚   â”œâ”€â”€ pydantic_demo.py
â”‚   â””â”€â”€ typeddict_demo.py
â”‚
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ test.py                         # Testing utilities
â””â”€â”€ .gitignore                      # Git ignore file
```

## âœ¨ Features

### LLMs
- OpenAI API integration
- HuggingFace model support
- String output parsing
- JSON output parsing

### Chat Models
- Multi-provider integration (OpenAI, Anthropic, Google, HuggingFace)
- API and local model support
- Streaming responses
- Context management

### Embeddings
- Document embedding generation
- Semantic similarity search
- Vector space operations

### RAG System
- **Document Loading**: PDF, CSV, Text, Web, Directory
- **Text Splitting**: Length-based, semantic, markdown, code-aware
- **Vector Stores**: ChromaDB integration with persistent storage
- **Retrieval**: Semantic search and ranking

### AI Agents
- Custom tool creation
- Built-in tool integration (DuckDuckGo, Shell)
- Tool chaining and orchestration
- Structured outputs

### Chains
- Simple chains for basic workflows
- Sequential chains for multi-step processes
- Parallel chains for concurrent operations
- Conditional chains for branching logic

### Advanced Features
- Message placeholders for dynamic prompts
- Chat history management
- Temperature control for response variation
- Structured outputs with Pydantic
- TypedDict for type-safe data structures

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- pip or conda

### Setup

1. **Clone the Repository**
```bash
git clone https://github.com/rajshekharbind/LLM-GenAI-RAG-AI-Agents-scalable-GitHub-worthy.git
cd LANG-CHAINS-REPO
```

2. **Create Virtual Environment**
```bash
# Using venv
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Linux/Mac)
source venv/bin/activate
```

3. **Install Dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure Environment Variables**
```bash
# Create .env file with your API keys
cp .env.example .env

# Edit .env and add:
# OPENAI_API_KEY=your_key_here
# HUGGINGFACE_API_KEY=your_key_here
# ANTHROPIC_API_KEY=your_key_here
# GOOGLE_API_KEY=your_key_here
```

## ğŸ“– Usage

### Basic LLM Usage
```python
from langchain.llms import OpenAI

llm = OpenAI(api_key="your_api_key")
response = llm("What is AI?")
print(response)
```

### Chat Model Usage
```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

chat = ChatOpenAI()
messages = [HumanMessage(content="Hello!")]
response = chat(messages)
```

### RAG Pipeline
```python
from langchain.document_loaders import PDFLoader
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

# Load documents
loader = PDFLoader("document.pdf")
documents = loader.load()

# Create embeddings
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(documents, embeddings)

# Retrieve
results = vectorstore.similarity_search("query")
```

### Agent with Tools
```python
from langchain.agents import AgentType, initialize_agent
from langchain.tools import DuckDuckGoSearchRun

tools = [DuckDuckGoSearchRun()]
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)

result = agent.run("What is the capital of France?")
```

## ğŸ¬ Quick Start Examples

### Example 1: Simple Prompt Template
See `prompt/prompt_template.py`

### Example 2: Document Q&A
See `RAG-APPLICATION/Youtube-Chatbot-rag/app.py`

### Example 3: AI Agent with Tools
See `RAG-APPLICATION/Building-end-to-end-AI-Agent-in-llm/ai-agent.py`

### Example 4: Runnable Chains
See `Runnables-in-LangChain/runnable_sequence.py`

## ğŸ›  Technologies

- **LangChain**: Core framework for building LLM applications
- **OpenAI**: GPT-3.5, GPT-4 models
- **Anthropic**: Claude models
- **Google**: Vertex AI
- **HuggingFace**: Open-source models and transformers
- **ChromaDB**: Vector database
- **Pydantic**: Data validation
- **Flask/Streamlit**: Web frameworks
- **Python 3.8+**: Development language

## ğŸ”‘ Key Components Explained

### 1. LLMs Folder
Direct LLM integration for text completion and generation tasks.

### 2. ChatModels Folder
Conversational AI with context awareness and multi-turn support.

### 3. Embeddings
Converting text to dense vectors for semantic search and similarity.

### 4. RAG Application
Complete retrieval-augmented generation pipeline combining retrieval and generation.

### 5. Chains
Composable pipelines for complex workflows.

### 6. Agents
Autonomous systems that use tools to accomplish goals.

### 7. Runnables
Modern LangChain patterns for building production applications.

## ğŸ“š Examples & Tutorials

Each folder contains runnable examples. To execute:

```bash
# Run any Python file
python 1.LLMs/1_llm_demo.py

# For interactive notebooks
jupyter notebook
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ Best Practices

- Keep API keys in `.env` file (never commit)
- Use virtual environment for isolated dependencies
- Follow PEP 8 style guidelines
- Add docstrings to functions
- Test code before pushing
- Use type hints for better code clarity
- Document complex logic with comments

## ğŸ› Troubleshooting

### Common Issues

1. **API Key not found**
   - Ensure `.env` file exists in root directory
   - Verify API keys are correctly set

2. **Module not found**
   - Run `pip install -r requirements.txt`
   - Ensure virtual environment is activated

3. **Vector store errors**
   - Ensure ChromaDB is installed
   - Check database file permissions

## ğŸ“ Support

For issues and questions:
- Open an issue on GitHub
- Review existing examples in each folder
- Check LangChain documentation: https://python.langchain.com

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Author

**Raj Shekhar**
- GitHub: [@rajshekharbind](https://github.com/rajshekharbind)
- Email: rajshekhar@github.com

## ğŸ”— Links

- **Repository**: [LLM-GenAI-RAG-AI-Agents](https://github.com/rajshekharbind/LLM-GenAI-RAG-AI-Agents-scalable-GitHub-worthy)
- **LangChain Docs**: https://python.langchain.com
- **OpenAI API**: https://platform.openai.com
- **HuggingFace**: https://huggingface.co

## ğŸ“ Learning Resources

- LangChain Official Documentation
- OpenAI API Documentation
- Semantic Search and Embeddings
- Prompt Engineering Best Practices
- Retrieval Augmented Generation (RAG) Patterns

---

**Last Updated**: February 2026

**Status**: âœ… Active Development

**Star** â­ if you find this project helpful!
